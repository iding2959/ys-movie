"""
Wan2.2 å›¾ç”Ÿè§†é¢‘ API
æ ¹æ®æ—¶é•¿è‡ªåŠ¨æ‹¼æ¥æˆ–åˆ é™¤èŠ‚ç‚¹ç”Ÿæˆè§†é¢‘
"""
from fastapi import APIRouter, HTTPException, BackgroundTasks, UploadFile, File, Form
from core.comfyui_client import ComfyUIClient
from core.models import TaskResponse
from core.managers import TaskManager, ConnectionManager
from core.response import R, ResponseModel
from pydantic import BaseModel, Field, model_validator
from typing import Optional, Dict, Any, List, Union
from datetime import datetime
import json
import logging
import copy
import random

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/wan22_i2v", tags=["Wan2.2è§†é¢‘ç”Ÿæˆ"])


class Wan22I2VRequest(BaseModel):
  """
  Wan2.2 å›¾ç”Ÿè§†é¢‘è¯·æ±‚
  
  æç¤ºè¯å‚æ•°è¯´æ˜:
    prompt: å•ä¸ªå­—ç¬¦ä¸²ï¼Œé€‚ç”¨äºçŸ­è§†é¢‘æˆ–æ‰€æœ‰ç‰‡æ®µä½¿ç”¨ç›¸åŒæç¤ºè¯
      ç¤ºä¾‹: "ä¸€ä¸ªå¥³å­©åœ¨æµ·è¾¹æ•£æ­¥ï¼Œé˜³å…‰æ˜åªš"
    
    æˆ–ä½¿ç”¨æç¤ºè¯åˆ—è¡¨ï¼ˆæ¨èï¼‰ï¼Œä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›ç‹¬ç«‹æç¤ºè¯:
      ç¤ºä¾‹1 (10ç§’): ["ç¬¬ä¸€æ®µï¼šå¥³å­©èµ°å‘æµ·è¾¹", "ç¬¬äºŒæ®µï¼šå¥³å­©åœ¨æµ·è¾¹æ¬£èµæ—¥è½"]
      ç¤ºä¾‹2 (15ç§’): ["å¼€å§‹ï¼šå¥³å­©å‡ºå‘", "ä¸­é—´ï¼šèµ°åœ¨è·¯ä¸Š", "ç»“å°¾ï¼šåˆ°è¾¾æµ·è¾¹"]
      ç¤ºä¾‹3 (20ç§’): ["ç‰‡æ®µ1æè¿°", "ç‰‡æ®µ2æè¿°", "ç‰‡æ®µ3æè¿°", "ç‰‡æ®µ4æè¿°"]
  
  æ³¨æ„: ä½¿ç”¨åˆ—è¡¨æ—¶ï¼Œæç¤ºè¯æ•°é‡å¿…é¡»ç­‰äº duration/5
  """
  prompt: Union[str, List[str]] = Field(
    ..., 
    description="è§†é¢‘æè¿°æç¤ºè¯ã€‚å¯ä»¥æ˜¯å•ä¸ªå­—ç¬¦ä¸²æˆ–æ¯ä¸ª5ç§’ç‰‡æ®µå¯¹åº”çš„æç¤ºè¯åˆ—è¡¨ã€‚å»ºè®®ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”æç¤ºè¯ä»¥è·å¾—æ›´å¥½æ•ˆæœ"
  )
  negative_prompt: str = Field(default="", description="è´Ÿé¢æç¤ºè¯")
  duration: int = Field(default=5, ge=5, le=30, description="è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ5-30ç§’ï¼Œæ­¥é•¿ä¸º5ç§’")
  width: int = Field(default=480, ge=256, le=1920, description="è§†é¢‘å®½åº¦")
  height: int = Field(default=832, ge=256, le=1920, description="è§†é¢‘é«˜åº¦")
  frame_rate: int = Field(default=16, ge=8, le=30, description="å¸§ç‡")
  steps: int = Field(default=4, ge=1, le=20, description="é‡‡æ ·æ­¥æ•°")
  seed: int = Field(default=-1, description="éšæœºç§å­ï¼Œ-1ä¸ºéšæœº")
  image_filename: Optional[str] = Field(None, description="èµ·å§‹å›¾ç‰‡æ–‡ä»¶åï¼ˆå·²ä¸Šä¼ åˆ°inputæ–‡ä»¶å¤¹ï¼‰")
  
  @model_validator(mode='after')
  def validate_prompt_and_duration(self):
    """éªŒè¯æç¤ºè¯ä¸æ—¶é•¿çš„åŒ¹é…"""
    num_segments = self.duration // 5
    
    if isinstance(self.prompt, str):
      # å•ä¸ªæç¤ºè¯ï¼Œå¦‚æœæ—¶é•¿è¶…è¿‡5ç§’ï¼Œå‘å‡ºè­¦å‘Š
      if num_segments > 1:
        logger.warning(
          f"âš ï¸ ä»…æä¾›äº†1ä¸ªæç¤ºè¯ï¼Œä½†è§†é¢‘æ—¶é•¿ä¸º{self.duration}ç§’ï¼ˆ{num_segments}ä¸ªç‰‡æ®µï¼‰ã€‚"
          f"å»ºè®®ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”çš„æç¤ºè¯ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºæ•ˆæœ"
        )
    elif isinstance(self.prompt, list):
      # æç¤ºè¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
      if len(self.prompt) != num_segments:
        raise ValueError(
          f"æç¤ºè¯æ•°é‡({len(self.prompt)})ä¸è§†é¢‘ç‰‡æ®µæ•°é‡({num_segments})ä¸åŒ¹é…ã€‚"
          f"{self.duration}ç§’è§†é¢‘éœ€è¦{num_segments}ä¸ªæç¤ºè¯"
        )
    else:
      raise ValueError("promptå¿…é¡»æ˜¯å­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨")
    
    return self


def setup_wan22_i2v_routes(
  comfyui_server: str,
  task_manager: TaskManager,
  connection_manager: ConnectionManager,
  protocol: str = "http",
  ws_protocol: str = "ws"
):
  """
  è®¾ç½®Wan2.2è§†é¢‘ç”Ÿæˆè·¯ç”±
  
  Args:
    comfyui_server: ComfyUI æœåŠ¡å™¨åœ°å€
    task_manager: ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
    connection_manager: WebSocket è¿æ¥ç®¡ç†å™¨å®ä¾‹
  """
  
  async def wait_for_completion(prompt_id: str, timeout: int):
    """ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆåå°ä»»åŠ¡ï¼‰"""
    try:
      task_manager.update_task(prompt_id, {"status": "running"})
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "running"
      }))
      
      logger.info(f"å¼€å§‹ç­‰å¾…Wan2.2è§†é¢‘ä»»åŠ¡å®Œæˆ: {prompt_id}")
      
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        result = await client.async_wait_for_completion(prompt_id, timeout)
        outputs = client.extract_outputs(result)
        
        final_result = {
          "prompt_id": prompt_id,
          "status": "completed",
          "outputs": outputs,
          "raw_result": result
        }
      
      task_manager.update_task(prompt_id, {
        "status": "completed",
        "result": final_result,
        "completed_at": datetime.now().isoformat()
      })
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "completed",
        "result": final_result
      }))
      
    except Exception as e:
      logger.error(f"æ‰§è¡ŒWan2.2è§†é¢‘ä»»åŠ¡ {prompt_id} å¤±è´¥: {e}")
      error_msg = str(e)
      
      task_manager.update_task(prompt_id, {
        "status": "failed",
        "error": error_msg,
        "failed_at": datetime.now().isoformat()
      })
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "failed",
        "error": error_msg
      }))
  
  @router.post("/analyze_image", response_model=ResponseModel)
  async def analyze_image(image: UploadFile = File(...)):
    """
    åˆ†æä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¿”å›å»ºè®®çš„è§†é¢‘å°ºå¯¸
    ä¿æŒå›¾ç‰‡æ¯”ä¾‹ï¼Œé•¿è¾¹å¯¹é½åˆ°832æˆ–ç”¨æˆ·æŒ‡å®šå€¼
    """
    try:
      image_data = await image.read()
      
      # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ˆé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜ï¼‰
      from pathlib import Path
      import uuid
      from datetime import datetime
      file_ext = Path(image.filename).suffix.lower()
      safe_filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}{file_ext}"
      
      # ä¸Šä¼ åˆ°ComfyUI
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        upload_result = await client.async_upload_image(
          image_data=image_data,
          filename=safe_filename,
          overwrite=True
        )
      
      uploaded_filename = upload_result.get('name', safe_filename)
      
      # ä½¿ç”¨PILè¯»å–å›¾ç‰‡å°ºå¯¸
      try:
        from PIL import Image
        from io import BytesIO
        img = Image.open(BytesIO(image_data))
        orig_width, orig_height = img.size
        
        # è®¡ç®—æœ€ä½³è§†é¢‘å°ºå¯¸
        # ä¿æŒæ¯”ä¾‹ï¼Œé•¿è¾¹832ï¼Œå¿…é¡»å¯¹é½åˆ°32çš„å€æ•°ï¼ˆWan2.2æ¨¡å‹è¦æ±‚ï¼‰
        if orig_width >= orig_height:
          # æ¨ªå±
          target_width = 832
          target_height = int(round(orig_height * 832 / orig_width))
        else:
          # ç«–å±
          target_height = 832
          target_width = int(round(orig_width * 832 / orig_height))
        
        # å¯¹é½åˆ°32çš„å€æ•°ï¼ˆæ¨¡å‹è¦æ±‚ï¼Œé¿å…å¼ é‡ç»´åº¦ä¸åŒ¹é…ï¼‰
        target_width = max(256, min(1920, (target_width // 32) * 32))
        target_height = max(256, min(1920, (target_height // 32) * 32))
        
        # 32çš„å€æ•°è‡ªåŠ¨æ»¡è¶³å¶æ•°è¦æ±‚ï¼Œä½†å†æ¬¡ç¡®ä¿
        if target_width % 2 == 1:
          target_width = ((target_width // 32) + 1) * 32
        if target_height % 2 == 1:
          target_height = ((target_height // 32) + 1) * 32
        
        aspect_ratio = orig_width / orig_height
        
      except Exception as e:
        logger.warning(f"æ— æ³•è§£æå›¾ç‰‡å°ºå¯¸: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        orig_width, orig_height = 480, 832
        target_width, target_height = 480, 832
        aspect_ratio = 480 / 832
      
      return R.success(
        data={
          "filename": uploaded_filename,
          "original_width": orig_width,
          "original_height": orig_height,
          "suggested_width": target_width,
          "suggested_height": target_height,
          "aspect_ratio": round(aspect_ratio, 4)
        },
        message="å›¾ç‰‡åˆ†æå®Œæˆ"
      )
      
    except Exception as e:
      logger.error(f"åˆ†æå›¾ç‰‡å¤±è´¥: {e}")
      return R.server_error(message=f"åˆ†æå›¾ç‰‡å¤±è´¥: {str(e)}")
  
  @router.post("/upload_and_generate", response_model=ResponseModel)
  async def upload_and_generate(
    background_tasks: BackgroundTasks,
    image: UploadFile = File(...),
    prompt: Optional[str] = Form(None),
    prompts: Optional[str] = Form(None, description="æç¤ºè¯åˆ—è¡¨ï¼ˆJSONå­—ç¬¦ä¸²ï¼‰ï¼Œä¼˜å…ˆçº§é«˜äºprompt"),
    negative_prompt: str = Form(default=""),
    duration: int = Form(default=5, ge=5, le=30),
    width: Optional[int] = Form(None, ge=256, le=1920),
    height: Optional[int] = Form(None, ge=256, le=1920),
    frame_rate: int = Form(default=16, ge=8, le=30),
    steps: int = Form(default=4, ge=1, le=20),
    seed: int = Form(default=-1),
    auto_size: bool = Form(default=True, description="è‡ªåŠ¨è®¡ç®—æœ€ä½³å°ºå¯¸")
  ):
    """
    ä¸Šä¼ å›¾ç‰‡å¹¶ç”Ÿæˆè§†é¢‘ï¼ˆä¸€æ­¥åˆ°ä½ï¼‰
    
    å‚æ•°è¯´æ˜:
      image: èµ·å§‹å›¾ç‰‡æ–‡ä»¶
      prompt: å•ä¸ªè§†é¢‘æè¿°æç¤ºè¯ï¼ˆé€‚ç”¨äºçŸ­è§†é¢‘æˆ–æ‰€æœ‰ç‰‡æ®µä½¿ç”¨ç›¸åŒæç¤ºè¯ï¼‰
      prompts: æç¤ºè¯åˆ—è¡¨ï¼ˆJSONå­—ç¬¦ä¸²æ ¼å¼ï¼‰ï¼Œä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”æç¤ºè¯ï¼Œå»ºè®®ä½¿ç”¨ä»¥è·å¾—æ›´å¥½æ•ˆæœ
      negative_prompt: è´Ÿé¢æç¤ºè¯
      duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œ5-30ç§’ï¼Œæ­¥é•¿ä¸º5ç§’
      width: è§†é¢‘å®½åº¦ï¼ˆå¯é€‰ï¼Œä¸å¡«æˆ–auto_size=Trueæ—¶è‡ªåŠ¨è®¡ç®—ï¼‰
      height: è§†é¢‘é«˜åº¦ï¼ˆå¯é€‰ï¼Œä¸å¡«æˆ–auto_size=Trueæ—¶è‡ªåŠ¨è®¡ç®—ï¼‰
      frame_rate: å¸§ç‡
      steps: é‡‡æ ·æ­¥æ•°
      seed: éšæœºç§å­ï¼Œ-1ä¸ºéšæœº
      auto_size: æ˜¯å¦è‡ªåŠ¨è®¡ç®—æœ€ä½³å°ºå¯¸ï¼ˆé»˜è®¤Trueï¼‰ï¼Œå¼€å¯åä¼šå¿½ç•¥width/heightå‚æ•°
    
    æç¤ºè¯å‚æ•°è¯´æ˜:
      - prompt å’Œ prompts å‚æ•°äºŒé€‰ä¸€ï¼Œä¸èƒ½åŒæ—¶æä¾›
      - prompt: å•ä¸ªå­—ç¬¦ä¸²ï¼Œæ‰€æœ‰ç‰‡æ®µä½¿ç”¨ç›¸åŒæç¤ºè¯
        ç¤ºä¾‹: "ä¸€ä¸ªå¥³å­©åœ¨æµ·è¾¹æ•£æ­¥ï¼Œé˜³å…‰æ˜åªš"
      
      - prompts: JSONæ•°ç»„å­—ç¬¦ä¸²ï¼Œä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›ç‹¬ç«‹æç¤ºè¯ï¼ˆæ¨èï¼‰
        ç¤ºä¾‹1 (10ç§’è§†é¢‘): '["ç¬¬ä¸€æ®µï¼šå¥³å­©èµ°å‘æµ·è¾¹", "ç¬¬äºŒæ®µï¼šå¥³å­©åœ¨æµ·è¾¹æ¬£èµæ—¥è½"]'
        ç¤ºä¾‹2 (15ç§’è§†é¢‘): '["å¼€å§‹ï¼šå¥³å­©å‡ºå‘", "ä¸­é—´ï¼šèµ°åœ¨è·¯ä¸Š", "ç»“å°¾ï¼šåˆ°è¾¾æµ·è¾¹"]'
        ç¤ºä¾‹3 (20ç§’è§†é¢‘): '["ç‰‡æ®µ1æè¿°", "ç‰‡æ®µ2æè¿°", "ç‰‡æ®µ3æè¿°", "ç‰‡æ®µ4æè¿°"]'
    
    è§†é¢‘å°ºå¯¸è¯´æ˜:
      - ä¸ä¼ width/heightæˆ–auto_size=True: è‡ªåŠ¨æ ¹æ®å›¾ç‰‡æ¯”ä¾‹è®¡ç®—æœ€ä½³å°ºå¯¸ï¼ˆæ¨èï¼‰
      - ä¼ å…¥width/heightä¸”auto_size=False: ä½¿ç”¨æŒ‡å®šå°ºå¯¸
      - å°ºå¯¸ä¼šè‡ªåŠ¨å¯¹é½åˆ°32çš„å€æ•°ï¼ˆæ¨¡å‹è¦æ±‚ï¼‰
    
    æ³¨æ„äº‹é¡¹:
      - è§†é¢‘æ—¶é•¿å¿…é¡»æ˜¯5çš„å€æ•°ï¼ˆ5ç§’ã€10ç§’ã€15ç§’ç­‰ï¼‰
      - ä½¿ç”¨promptsæ—¶ï¼Œæç¤ºè¯æ•°é‡å¿…é¡»ç­‰äº duration/5
      - ä¾‹å¦‚15ç§’è§†é¢‘éœ€è¦3ä¸ªæç¤ºè¯ï¼Œ20ç§’è§†é¢‘éœ€è¦4ä¸ªæç¤ºè¯
    """
    try:
      # éªŒè¯æç¤ºè¯å‚æ•°ï¼šå¿…é¡»æä¾›å…¶ä¸­ä¸€ä¸ªï¼Œä¸”ä¸èƒ½åŒæ—¶æä¾›
      if not prompt and not prompts:
        return R.client_error(message="å¿…é¡»æä¾›promptæˆ–promptså‚æ•°ä¹‹ä¸€")
      
      if prompt and prompts:
        return R.client_error(message="promptå’Œpromptså‚æ•°åªèƒ½æä¾›å…¶ä¸­ä¸€ä¸ªï¼Œä¸èƒ½åŒæ—¶ä½¿ç”¨")
      
      # è§£ææç¤ºè¯
      num_segments = duration // 5
      
      if prompts:
        # ä½¿ç”¨promptså‚æ•°ï¼ˆJSONæ•°ç»„ï¼‰
        try:
          prompt_list = json.loads(prompts)
          if not isinstance(prompt_list, list):
            return R.client_error(message="promptså¿…é¡»æ˜¯JSONæ•°ç»„æ ¼å¼")
          if len(prompt_list) != num_segments:
            return R.client_error(
              message=f"æç¤ºè¯æ•°é‡({len(prompt_list)})ä¸è§†é¢‘ç‰‡æ®µæ•°é‡({num_segments})ä¸åŒ¹é…ã€‚"
                     f"{duration}ç§’è§†é¢‘éœ€è¦{num_segments}ä¸ªæç¤ºè¯"
            )
          prompt_value = prompt_list
        except json.JSONDecodeError as e:
          return R.client_error(message=f"promptså‚æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²: {str(e)}")
      else:
        # ä½¿ç”¨promptå‚æ•°ï¼ˆå•ä¸ªå­—ç¬¦ä¸²ï¼‰
        prompt_value = prompt
        if num_segments > 1:
          logger.warning(
            f"âš ï¸ ä»…æä¾›äº†1ä¸ªæç¤ºè¯ï¼Œä½†è§†é¢‘æ—¶é•¿ä¸º{duration}ç§’ï¼ˆ{num_segments}ä¸ªç‰‡æ®µï¼‰ã€‚"
            f"å»ºè®®ä½¿ç”¨promptså‚æ•°ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”çš„æç¤ºè¯ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºæ•ˆæœ"
          )
      
      # 1. ä¸Šä¼ å›¾ç‰‡
      image_data = await image.read()
      
      # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼ˆé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜ï¼‰
      from pathlib import Path
      import uuid
      from datetime import datetime
      file_ext = Path(image.filename).suffix.lower()
      safe_filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}{file_ext}"
      
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        upload_result = await client.async_upload_image(
          image_data=image_data,
          filename=safe_filename,
          overwrite=True
        )
      
      uploaded_filename = upload_result.get('name', safe_filename)
      logger.info(f"å›¾ç‰‡ä¸Šä¼ æˆåŠŸ: {image.filename} -> {uploaded_filename}")
      
      # 1.5 è‡ªåŠ¨è®¡ç®—æœ€ä½³å°ºå¯¸ï¼ˆå¦‚æœå¯ç”¨æˆ–æœªæä¾›å°ºå¯¸ï¼‰
      final_width = width
      final_height = height
      
      if auto_size or width is None or height is None:
        try:
          from PIL import Image
          from io import BytesIO
          img = Image.open(BytesIO(image_data))
          orig_width, orig_height = img.size
          
          # è®¡ç®—æœ€ä½³è§†é¢‘å°ºå¯¸ï¼ˆä¿æŒæ¯”ä¾‹ï¼Œé•¿è¾¹832ï¼Œå¯¹é½åˆ°32çš„å€æ•°ï¼‰
          if orig_width >= orig_height:
            # æ¨ªå±
            target_width = 832
            target_height = int(round(orig_height * 832 / orig_width))
          else:
            # ç«–å±
            target_height = 832
            target_width = int(round(orig_width * 832 / orig_height))
          
          # å¯¹é½åˆ°32çš„å€æ•°ï¼ˆæ¨¡å‹è¦æ±‚ï¼‰
          final_width = max(256, min(1920, (target_width // 32) * 32))
          final_height = max(256, min(1920, (target_height // 32) * 32))
          
          # ç¡®ä¿æ˜¯å¶æ•°
          if final_width % 2 == 1:
            final_width = ((final_width // 32) + 1) * 32
          if final_height % 2 == 1:
            final_height = ((final_height // 32) + 1) * 32
          
          logger.info(f"ğŸ“ è‡ªåŠ¨è®¡ç®—è§†é¢‘å°ºå¯¸: {orig_width}x{orig_height} -> {final_width}x{final_height}")
          
        except Exception as e:
          logger.warning(f"æ— æ³•è§£æå›¾ç‰‡å°ºå¯¸: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
          final_width = width if width else 480
          final_height = height if height else 832
      
      # 2. ç”Ÿæˆworkflow
      workflow = generate_wan22_workflow(
        image_filename=uploaded_filename,
        prompt=prompt_value,
        negative_prompt=negative_prompt,
        duration=duration,
        width=final_width,
        height=final_height,
        frame_rate=frame_rate,
        steps=steps,
        seed=seed
      )
      
      # 3. æäº¤åˆ°ComfyUI
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        response = await client.async_queue_prompt(workflow)
        
      if not response or 'prompt_id' not in response:
        error_detail = response.get('error', 'æœªçŸ¥é”™è¯¯') if response else 'æ— å“åº”'
        node_errors = response.get('node_errors', {}) if response else {}
        
        error_msg = f"ComfyUIæäº¤å¤±è´¥: {error_detail}"
        if node_errors:
          error_msg += f", èŠ‚ç‚¹é”™è¯¯: {json.dumps(node_errors, ensure_ascii=False)}"
        
        raise HTTPException(
          status_code=500,
          detail=error_msg
        )
      
      prompt_id = response['prompt_id']
      
      # 4. æ·»åŠ ä»»åŠ¡åˆ°ç®¡ç†å™¨
      num_segments = duration // 5
      task_manager.add_task(prompt_id, {
        "task_id": prompt_id,
        "prompt_id": prompt_id,
        "workflow_type": "wan22_i2v",
        "params": {
          "prompt": prompt_value,
          "duration": duration,
          "width": final_width,
          "height": final_height,
          "image": uploaded_filename
        }
      })
      
      # 5. åœ¨åå°ç­‰å¾…ä»»åŠ¡å®Œæˆ
      timeout = max(600, duration * 30)  # æ ¹æ®æ—¶é•¿åŠ¨æ€è®¾ç½®è¶…æ—¶
      background_tasks.add_task(wait_for_completion, prompt_id, timeout)
      
      logger.info(f"ğŸ“¹ Wan2.2è§†é¢‘ä»»åŠ¡å·²æäº¤: {prompt_id}, æ—¶é•¿: {duration}ç§’, å°ºå¯¸: {final_width}x{final_height}")
      
      response_data = {
        "task_id": prompt_id,
        "status": "submitted",
        "duration": duration,
        "segments": num_segments,
        "image": uploaded_filename,
        "prompt_count": 1 if isinstance(prompt_value, str) else len(prompt_value),
        "width": final_width,
        "height": final_height,
        "auto_size": auto_size
      }
      
      message = f"è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼ˆ{duration}ç§’, {final_width}x{final_height}ï¼‰"
      if isinstance(prompt_value, str) and num_segments > 1:
        warning_msg = f"ä»…æä¾›äº†1ä¸ªæç¤ºè¯ï¼Œä½†è§†é¢‘æœ‰{num_segments}ä¸ªç‰‡æ®µã€‚å»ºè®®ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”çš„æç¤ºè¯ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºæ•ˆæœ"
        response_data["warning"] = warning_msg
        message += f"ï¼Œ{warning_msg}"
      
      return R.success(
        data=response_data,
        message=message
      )
      
    except Exception as e:
      logger.error(f"ä¸Šä¼ å›¾ç‰‡å¹¶ç”Ÿæˆè§†é¢‘å¤±è´¥: {e}")
      return R.server_error(message=f"æ“ä½œå¤±è´¥: {str(e)}")
  
  @router.post("/generate", response_model=ResponseModel)
  async def generate_video(
    data: Wan22I2VRequest,
    background_tasks: BackgroundTasks
  ):
    """
    ä½¿ç”¨å·²ä¸Šä¼ çš„å›¾ç‰‡ç”Ÿæˆè§†é¢‘
    
    å‚æ•°:
      data: Wan2.2è§†é¢‘ç”Ÿæˆè¯·æ±‚å‚æ•°
      
    æ³¨æ„:
      - å¦‚æœè§†é¢‘æ—¶é•¿è¶…è¿‡5ç§’ï¼Œå»ºè®®ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”çš„æç¤ºè¯åˆ—è¡¨
      - ä»…æä¾›ä¸€ä¸ªæç¤ºè¯æ—¶ï¼Œæ‰€æœ‰ç‰‡æ®µå°†ä½¿ç”¨ç›¸åŒæç¤ºè¯ï¼Œå¯èƒ½å½±å“è¾“å‡ºæ•ˆæœ
    """
    try:
      if not data.image_filename:
        return R.client_error(message="å¿…é¡»æä¾›image_filenameå‚æ•°")
      
      # æ£€æŸ¥æç¤ºè¯æƒ…å†µå¹¶ç»™å‡ºè­¦å‘Š
      num_segments = data.duration // 5
      prompt_warning = None
      if isinstance(data.prompt, str) and num_segments > 1:
        prompt_warning = f"ä»…æä¾›äº†1ä¸ªæç¤ºè¯ï¼Œä½†è§†é¢‘æœ‰{num_segments}ä¸ªç‰‡æ®µã€‚å»ºè®®ä¸ºæ¯ä¸ª5ç§’ç‰‡æ®µæä¾›å¯¹åº”çš„æç¤ºè¯ä»¥è·å¾—æ›´å¥½çš„è¾“å‡ºæ•ˆæœ"
      
      # ç”Ÿæˆworkflow
      workflow = generate_wan22_workflow(
        image_filename=data.image_filename,
        prompt=data.prompt,
        negative_prompt=data.negative_prompt,
        duration=data.duration,
        width=data.width,
        height=data.height,
        frame_rate=data.frame_rate,
        steps=data.steps,
        seed=data.seed
      )
      
      # æäº¤åˆ°ComfyUI
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        response = await client.async_queue_prompt(workflow)
        
      if not response or 'prompt_id' not in response:
        error_detail = response.get('error', 'æœªçŸ¥é”™è¯¯') if response else 'æ— å“åº”'
        node_errors = response.get('node_errors', {}) if response else {}
        
        error_msg = f"ComfyUIæäº¤å¤±è´¥: {error_detail}"
        if node_errors:
          error_msg += f", èŠ‚ç‚¹é”™è¯¯: {json.dumps(node_errors, ensure_ascii=False)}"
        
        raise HTTPException(
          status_code=500,
          detail=error_msg
        )
      
      prompt_id = response['prompt_id']
      
      # æ·»åŠ ä»»åŠ¡åˆ°ç®¡ç†å™¨
      task_manager.add_task(prompt_id, {
        "task_id": prompt_id,
        "prompt_id": prompt_id,
        "workflow_type": "wan22_i2v",
        "params": data.dict()
      })
      
      # åœ¨åå°ç­‰å¾…ä»»åŠ¡å®Œæˆ
      timeout = max(600, data.duration * 30)
      background_tasks.add_task(wait_for_completion, prompt_id, timeout)
      
      logger.info(f"ğŸ“¹ Wan2.2è§†é¢‘ä»»åŠ¡å·²æäº¤: {prompt_id}, æ—¶é•¿: {data.duration}ç§’")
      
      response_data = {
        "task_id": prompt_id,
        "status": "submitted",
        "duration": data.duration,
        "segments": num_segments,
        "prompt_count": 1 if isinstance(data.prompt, str) else len(data.prompt)
      }
      
      message = f"è§†é¢‘ç”Ÿæˆä»»åŠ¡å·²æäº¤ï¼ˆ{data.duration}ç§’ï¼‰"
      if prompt_warning:
        response_data["warning"] = prompt_warning
        message += f"ï¼Œ{prompt_warning}"
      
      return R.success(
        data=response_data,
        message=message
      )
      
    except Exception as e:
      logger.error(f"ç”Ÿæˆè§†é¢‘å¤±è´¥: {e}")
      return R.server_error(message=f"ç”Ÿæˆè§†é¢‘å¤±è´¥: {str(e)}")
  
  return router


def generate_wan22_workflow(
  image_filename: str,
  prompt: Union[str, List[str]],
  negative_prompt: str = "",
  duration: int = 5,
  width: int = 480,
  height: int = 832,
  frame_rate: int = 16,
  steps: int = 4,
  seed: int = -1
) -> Dict[str, Any]:
  """
  æ ¹æ®å‚æ•°ç”ŸæˆWan2.2è§†é¢‘workflow
  
  Args:
    image_filename: èµ·å§‹å›¾ç‰‡æ–‡ä»¶å
    prompt: æç¤ºè¯ï¼ˆå­—ç¬¦ä¸²æˆ–æ¯ä¸ª5ç§’ç‰‡æ®µå¯¹åº”çš„æç¤ºè¯åˆ—è¡¨ï¼‰
    negative_prompt: è´Ÿé¢æç¤ºè¯
    duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    width: å®½åº¦
    height: é«˜åº¦
    frame_rate: å¸§ç‡
    steps: é‡‡æ ·æ­¥æ•°
    seed: éšæœºç§å­
    
  Returns:
    å®Œæ•´çš„workflowå­—å…¸
  """
  # è®¡ç®—éœ€è¦å¤šå°‘ä¸ª5ç§’ç‰‡æ®µ
  num_segments = duration // 5
  
  # æ ‡å‡†åŒ–æç¤ºè¯ï¼šè½¬æ¢ä¸ºåˆ—è¡¨
  if isinstance(prompt, str):
    prompts = [prompt] * num_segments
  else:
    prompts = prompt
  
  # éªŒè¯æç¤ºè¯æ•°é‡
  if len(prompts) != num_segments:
    raise ValueError(f"æç¤ºè¯æ•°é‡({len(prompts)})ä¸ç‰‡æ®µæ•°é‡({num_segments})ä¸åŒ¹é…")
  # è®¡ç®—æ¯ä¸ªç‰‡æ®µåº”ç”Ÿæˆçš„å¸§æ•°ï¼ˆç¡®ä¿æ€»æ—¶é•¿ç²¾ç¡®ï¼‰
  # åœ¨16FPSä¸‹ï¼Œå¼ºåˆ¶æ¯ä¸ª5ç§’ç‰‡æ®µè¾“å‡º81å¸§ï¼Œé¿å…å®¹å™¨/åˆæˆæ—¶é•¿åçŸ­
  segment_length = 81 if frame_rate == 16 else int(round(5 * frame_rate))
  # ç‰‡æ®µä¹‹é—´ç”¨äºè¿ç»­æ€§çš„å‚è€ƒå¸§æ•°é‡ï¼ˆç”¨äºä½œä¸ºä¸‹ä¸€æ®µçš„èµ·å§‹æ¡ä»¶ï¼Œä¸å‚ä¸è£å‰ªï¼‰
  # è¿‡æ¸¡å‚è€ƒå¸§ï¼šå¢å¤§åˆ°çº¦1ç§’å†…æˆ–è‡³å°‘8å¸§ï¼Œæœ€å¤š24å¸§ï¼Œæå‡è¡”æ¥ç¨³å®šæ€§
  overlap_frames = max(8, min(24, int(round(frame_rate))))
  
  if seed == -1:
    seed = random.randint(0, 18446744073709551615)
  
  # åŸºç¡€èŠ‚ç‚¹ï¼ˆæ‰€æœ‰workflowå…±ç”¨ï¼‰
  workflow = {
    "16": {
      "inputs": {"image": image_filename},
      "class_type": "LoadImage",
      "_meta": {"title": "Start Frame"}
    },
    "26": {
      "inputs": {"ckpt_name": "wan2.2-rapid-mega-aio-v12.safetensors"},
      "class_type": "CheckpointLoaderSimple",
      "_meta": {"title": "Load Checkpoint"}
    },
    "32": {
      "inputs": {"shift": 8, "model": ["26", 0]},
      "class_type": "ModelSamplingSD3",
      "_meta": {"title": "ModelSampling"}
    },
    "44": {
      "inputs": {"value": frame_rate},
      "class_type": "Float",
      "_meta": {"title": "Frame Rate"}
    },
    "57": {
      "inputs": {
        "mode": "Manual",
        "width": width,
        "height": height,
        "auto_detect": True,
        "rescale_mode": "resolution",
        "rescale_value": 2.27866357593825,
        "input_image": ["16", 0]
      },
      "class_type": "ResolutionMaster",
      "_meta": {"title": "Resolution Master"}
    },
    "58": {
      "inputs": {
        "width": ["57", 0],
        "height": ["57", 1],
        "upscale_method": "nearest-exact",
        "keep_proportion": "stretch",
        "pad_color": "0, 0, 0",
        "crop_position": "center",
        "divisible_by": 2,
        "device": "cpu",
        "image": ["16", 0]
      },
      "class_type": "ImageResizeKJv2",
      "_meta": {"title": "Resize Image"}
    },
    "120": {
      "inputs": {"value": steps},
      "class_type": "PrimitiveInt",
      "_meta": {"title": "steps"}
    }
  }
  
  # ä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆå”¯ä¸€çš„ç§å­
  segment_seeds = [seed + i * 1000000 for i in range(num_segments)]
  
  # æ ¹æ®ç‰‡æ®µæ•°é‡ç”Ÿæˆå¯¹åº”çš„èŠ‚ç‚¹
  if num_segments == 1:
    # å•ä¸ª5ç§’ç‰‡æ®µ
    workflow.update(
      generate_single_segment(
        index=0,
        seed=segment_seeds[0],
        prompt=prompts[0],
        negative_prompt=negative_prompt,
        segment_length=segment_length,
        overlap_frames=overlap_frames,
        prefix="70"
      )
    )
    # æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹
    workflow["39"] = {
      "inputs": {
        "frame_rate": ["44", 0],
        "loop_count": 0,
        "filename_prefix": "wan2.2_video",
        "format": "video/h264-mp4",
        "pix_fmt": "yuv420p",
        "crf": 19,
        "save_metadata": True,
        "trim_to_audio": False,
        "pingpong": False,
        "save_output": True,
        "images": ["70:11", 0]
      },
      "class_type": "VHS_VideoCombine",
      "_meta": {"title": "Video Output"}
    }
  else:
    # å¤šä¸ªç‰‡æ®µéœ€è¦æ‹¼æ¥
    # ç¬¬ä¸€ä¸ªç‰‡æ®µ
    workflow.update(
      generate_single_segment(
        index=0,
        seed=segment_seeds[0],
        prompt=prompts[0],
        negative_prompt=negative_prompt,
        segment_length=segment_length,
        overlap_frames=overlap_frames,
        prefix="70"
      )
    )
    
    # ä¸­é—´ç‰‡æ®µ
    for i in range(1, num_segments):
      prev_prefix = f"{70 + (i-1)*6}" if i == 1 else f"{70 + (i-1)*6}"
      curr_prefix = f"{70 + i*6}"
      workflow.update(
        generate_linked_segment(
          index=i,
          seed=segment_seeds[i],
          prompt=prompts[i],
          negative_prompt=negative_prompt,
          prev_prefix=prev_prefix,
          curr_prefix=curr_prefix,
          segment_length=segment_length,
          overlap_frames=overlap_frames
        )
      )
    
    # æœ€ç»ˆæ‹¼æ¥å’Œè¾“å‡º
    workflow.update(generate_final_merge(num_segments=num_segments, overlap_frames=overlap_frames, segment_length=segment_length))
  
  return workflow


def generate_single_segment(
  index: int,
  seed: int,
  prompt: str,
  negative_prompt: str,
  segment_length: int,
  overlap_frames: int,
  prefix: str = "70"
) -> Dict[str, Any]:
  """ç”Ÿæˆå•ä¸ª5ç§’ç‰‡æ®µçš„èŠ‚ç‚¹ï¼ˆé•¿åº¦ä¸fpsç²¾ç¡®åŒ¹é…ï¼‰"""
  # å¯¹äºç¬¬0æ®µï¼ŒæŒ‰ segment_lengthï¼›å¯¹äºåç»­æ®µï¼Œé¢å¤–å¤šç”Ÿæˆ overlap_frames ä»¥ä¾¿è£å‰ª
  effective_length = segment_length if index == 0 else segment_length + overlap_frames
  # åç»­æ®µé™ä½ empty_frame_level ä»¥å¢å¼ºä¸å‰æ®µçš„è¿ç»­æ€§
  start_empty_level = 0.5 if index == 0 else 0.2
  return {
    f"{prefix}:34": {
      "inputs": {
        "num_frames": effective_length,
        "empty_frame_level": start_empty_level,
        "start_index": 0,
        "end_index": -1,
        "start_image": ["58", 0] if index == 0 else [f"{int(prefix)-6}:91", 0]
      },
      "class_type": "WanVideoVACEStartToEndFrame",
      "_meta": {"title": f"VACE Frame {index}"}
    },
    f"{prefix}:10": {
      "inputs": {
        "text": negative_prompt,
        "clip": ["26", 1]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {"title": "Negative Prompt"}
    },
    f"{prefix}:70": {
      "inputs": {"text": prompt},
      "class_type": "CR Text",
      "_meta": {"title": f"Prompt {index}"}
    },
    f"{prefix}:9": {
      "inputs": {
        "text": [f"{prefix}:70", 0],
        "clip": ["26", 1]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {"title": "Positive Prompt"}
    },
    f"{prefix}:28": {
      "inputs": {
        "width": ["58", 1],
        "height": ["58", 2],
        "length": effective_length,
        "batch_size": 1,
        "strength": 1,
        "positive": [f"{prefix}:9", 0],
        "negative": [f"{prefix}:10", 0],
        "vae": ["26", 2],
        "control_video": [f"{prefix}:34", 0],
        "control_masks": [f"{prefix}:34", 1]
      },
      "class_type": "WanVaceToVideo",
      "_meta": {"title": "VaceToVideo"}
    },
    f"{prefix}:8": {
      "inputs": {
        "seed": seed,
        "steps": ["120", 0],
        "cfg": 1,
        "sampler_name": "ipndm",
        "scheduler": "sgm_uniform",
        "denoise": 1,
        "model": ["32", 0],
        "positive": [f"{prefix}:28", 0],
        "negative": [f"{prefix}:28", 1],
        "latent_image": [f"{prefix}:28", 2]
      },
      "class_type": "KSampler",
      "_meta": {"title": "Sampler"}
    },
    f"{prefix}:11": {
      "inputs": {
        "samples": [f"{prefix}:8", 0],
        "vae": ["26", 2]
      },
      "class_type": "VAEDecode",
      "_meta": {"title": "VAE Decode"}
    },
    f"{prefix}:91": {
      "inputs": {
        "start_index": max(0, (segment_length if index == 0 else effective_length) - overlap_frames),
        "num_frames": overlap_frames,
        "images": [f"{prefix}:11", 0]
      },
      "class_type": "GetImageRangeFromBatch",
      "_meta": {"title": "Get End Frames"}
    }
  }


def generate_linked_segment(
  index: int,
  seed: int,
  prompt: str,
  negative_prompt: str,
  prev_prefix: str,
  curr_prefix: str,
  segment_length: int,
  overlap_frames: int
) -> Dict[str, Any]:
  """ç”Ÿæˆé“¾æ¥åˆ°å‰ä¸€ä¸ªç‰‡æ®µçš„èŠ‚ç‚¹ï¼ˆæ— é¢å¤–è£å‰ªï¼‰"""
  segment = generate_single_segment(
    index=index,
    seed=seed,
    prompt=prompt,
    negative_prompt=negative_prompt,
    segment_length=segment_length,
    overlap_frames=overlap_frames,
    prefix=curr_prefix
  )
  # ä¿®æ”¹start_imageé“¾æ¥åˆ°å‰ä¸€ä¸ªç‰‡æ®µæœ«å°¾è‹¥å¹²å¸§
  segment[f"{curr_prefix}:34"]["inputs"]["start_image"] = [f"{prev_prefix}:91", 0]
  return segment


def generate_final_merge(num_segments: int, overlap_frames: int, segment_length: int) -> Dict[str, Any]:
  """ç”Ÿæˆæœ€ç»ˆåˆå¹¶èŠ‚ç‚¹ï¼ˆå¯¹åç»­æ®µè£æ‰é¦– overlap_frames å¸§å†æ‹¼æ¥ï¼‰"""
  nodes = {}
  
  # é€æ­¥åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
  for i in range(1, num_segments):
    prefix = 70 + i * 6
    prev_prefix = 70 + (i - 1) * 6
    
    # ä¸ºå½“å‰æ®µåˆ›å»ºè£å‰ªèŠ‚ç‚¹ï¼šå»æ‰é¦– overlap_frames å¸§ï¼Œä¿ç•™ç²¾å‡† segment_length å¸§
    nodes[f"{prefix}:92"] = {
      "inputs": {
        "batch_index": overlap_frames,
        "length": segment_length,
        "image": [f"{prefix}:11", 0]
      },
      "class_type": "ImageFromBatch",
      "_meta": {"title": f"Trim Start {i}"}
    }
    
    if i == 1:
      # ç¬¬ä¸€æ¬¡åˆå¹¶ï¼šåˆå¹¶ç¬¬0å’Œç¬¬1ç‰‡æ®µï¼ˆç¬¬1æ®µå·²è£å‰ªé¦–é‡å å¸§ï¼‰
      nodes[f"{prefix}:88"] = {
        "inputs": {
          "inputcount": 2,
          "Update inputs": None,
          "image_1": ["70:11", 0],
          "image_2": [f"{prefix}:92", 0]
        },
        "class_type": "ImageBatchMulti",
        "_meta": {"title": "Merge 0-1"}
      }
    else:
      # åç»­åˆå¹¶ï¼šåˆå¹¶ä¹‹å‰çš„ç»“æœå’Œå·²è£å‰ªçš„å½“å‰ç‰‡æ®µ
      nodes[f"{prefix}:88"] = {
        "inputs": {
          "inputcount": 2,
          "Update inputs": None,
          "image_1": [f"{prev_prefix}:88", 0],
          "image_2": [f"{prefix}:92", 0]
        },
        "class_type": "ImageBatchMulti",
        "_meta": {"title": f"Merge 0-{i}"}
      }
  
  # æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹
  last_prefix = 70 + (num_segments - 1) * 6
  final_input = [f"{last_prefix}:88", 0] if num_segments > 1 else ["70:11", 0]
  
  # å¯é€‰ï¼šé¢œè‰²åŒ¹é…
  nodes["100"] = {
    "inputs": {
      "method": "mkl",
      "strength": 1,
      "multithread": True,
      "image_ref": ["16", 0],
      "image_target": final_input
    },
    "class_type": "ColorMatch",
    "_meta": {"title": "Color Match"}
  }
  
  # è§†é¢‘åˆæˆ
  nodes["39"] = {
    "inputs": {
      "frame_rate": ["44", 0],
      "loop_count": 0,
      "filename_prefix": "wan2.2_video",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": True,
      "trim_to_audio": False,
      "pingpong": False,
      "save_output": True,
      "images": ["100", 0]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {"title": "Video Output"}
  }
  
  return nodes

