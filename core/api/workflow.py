"""
å·¥ä½œæµç®¡ç†ç›¸å…³æ¥å£
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from core.comfyui_client import ComfyUIClient
from core.models import WorkflowSubmit, WorkflowUpdate, TaskResponse
from core.managers import TaskManager, ConnectionManager
from core.utils import apply_params_to_workflow
from core.response import R, ResponseModel
from pathlib import Path
from datetime import datetime
import json
import logging
import traceback

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api", tags=["å·¥ä½œæµç®¡ç†"])


def setup_workflow_routes(
  comfyui_server: str,
  task_manager: TaskManager,
  connection_manager: ConnectionManager,
  workflow_dir: Path,
  protocol: str = "http",
  ws_protocol: str = "ws"
):
  """
  è®¾ç½®å·¥ä½œæµç®¡ç†è·¯ç”±
  
  Args:
    comfyui_server: ComfyUI æœåŠ¡å™¨åœ°å€
    task_manager: ä»»åŠ¡ç®¡ç†å™¨å®ä¾‹
    connection_manager: WebSocket è¿æ¥ç®¡ç†å™¨å®ä¾‹
    workflow_dir: å·¥ä½œæµæ–‡ä»¶ç›®å½•
    protocol: HTTPåè®®
    ws_protocol: WebSocketåè®®
  """
  
  async def wait_for_completion(prompt_id: str, timeout: int):
    """ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆåå°ä»»åŠ¡ï¼‰"""
    try:
      task_manager.update_task(prompt_id, {"status": "running"})
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "running"
      }))
      
      logger.info(f"å¼€å§‹ç­‰å¾…ä»»åŠ¡å®Œæˆ: {prompt_id}")
      
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        result = await client.async_wait_for_completion(prompt_id, timeout)
        outputs = client.extract_outputs(result)
        
        final_result = {
          "prompt_id": prompt_id,
          "status": "completed",
          "outputs": outputs,
          "raw_result": result
        }
      
      task_manager.update_task(prompt_id, {
        "status": "completed",
        "result": final_result,
        "completed_at": datetime.now().isoformat()
      })
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "completed",
        "result": final_result
      }))
      
    except Exception as e:
      logger.error(f"æ‰§è¡Œä»»åŠ¡ {prompt_id} å¤±è´¥: {e}")
      error_msg = str(e)
      
      task_manager.update_task(prompt_id, {
        "status": "failed",
        "error": error_msg,
        "failed_at": datetime.now().isoformat()
      })
      
      await connection_manager.broadcast(json.dumps({
        "type": "task_update",
        "task_id": prompt_id,
        "status": "failed",
        "error": error_msg
      }))
  
  @router.post("/workflow/submit", response_model=ResponseModel)
  async def submit_workflow(
    data: WorkflowSubmit,
    background_tasks: BackgroundTasks
  ):
    """æäº¤å·¥ä½œæµä»»åŠ¡ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    try:
      # åº”ç”¨åŠ¨æ€å‚æ•°åˆ°å·¥ä½œæµ
      workflow = data.workflow
      if data.params:
        workflow = apply_params_to_workflow(workflow, data.params)
      
      # æäº¤åˆ°ComfyUI
      async with ComfyUIClient(comfyui_server, protocol, ws_protocol) as client:
        response = await client.async_queue_prompt(workflow)
        
      if not response or 'prompt_id' not in response:
        error_detail = response.get('error', 'æœªçŸ¥é”™è¯¯') if response else 'æ— å“åº”'
        node_errors = response.get('node_errors', {}) if response else {}
        
        error_msg = f"ComfyUIæäº¤å¤±è´¥: {error_detail}"
        if node_errors:
          error_msg += f", èŠ‚ç‚¹é”™è¯¯: {json.dumps(node_errors, ensure_ascii=False)}"
        
        raise HTTPException(
          status_code=500,
          detail=error_msg
        )
      
      prompt_id = response['prompt_id']
      
      # æ·»åŠ ä»»åŠ¡åˆ°ç®¡ç†å™¨
      task_manager.add_task(prompt_id, {
        "task_id": prompt_id,
        "prompt_id": prompt_id,
        "workflow_type": "custom",
        "params": data.params
      })
      
      # åœ¨åå°ç­‰å¾…ä»»åŠ¡å®Œæˆ
      background_tasks.add_task(wait_for_completion, prompt_id, data.timeout)
      
      logger.info(f"ğŸ“ å·¥ä½œæµä»»åŠ¡å·²æäº¤: {prompt_id}")
      
      return R.success(
        data={
          "task_id": prompt_id,
          "status": "submitted"
        },
        message="ä»»åŠ¡å·²æäº¤åˆ°é˜Ÿåˆ—"
      )
    except Exception as e:
      logger.error(f"æäº¤å·¥ä½œæµå¤±è´¥: {e}")
      return R.server_error(message=f"æäº¤å·¥ä½œæµå¤±è´¥: {str(e)}")
  
  @router.post("/workflow/upload")
  async def upload_workflow(file: UploadFile = File(...)):
    """ä¸Šä¼ å·¥ä½œæµæ–‡ä»¶"""
    if not file.filename.endswith('.json'):
      raise HTTPException(
        status_code=400,
        detail="åªæ”¯æŒJSONæ ¼å¼çš„å·¥ä½œæµæ–‡ä»¶"
      )
    
    file_path = workflow_dir / file.filename
    content = await file.read()
    
    try:
      # éªŒè¯JSONæ ¼å¼
      raw_workflow = json.loads(content)
      
      # æ£€æµ‹å¹¶è½¬æ¢å·¥ä½œæµæ ¼å¼
      if 'nodes' in raw_workflow and isinstance(raw_workflow['nodes'], list):
        # UIæ ¼å¼ - è½¬æ¢ä¸ºAPIæ ¼å¼
        logger.info(f"æ£€æµ‹åˆ°UIæ ¼å¼å·¥ä½œæµï¼Œæ­£åœ¨è½¬æ¢ä¸ºAPIæ ¼å¼")
        workflow = _convert_ui_to_api_format(raw_workflow)
      else:
        # å‡è®¾å·²ç»æ˜¯APIæ ¼å¼
        workflow = raw_workflow
      
      # ä¿å­˜åˆ°æ–‡ä»¶
      with open(file_path, 'wb') as f:
        f.write(content)
      
      return R.success(
        data={
          "filename": file.filename,
          "path": str(file_path),
          "nodes": len(workflow),
          "format": "UI" if 'nodes' in raw_workflow else "API",
          "workflow": workflow
        },
        message="å·¥ä½œæµä¸Šä¼ æˆåŠŸ"
      )
    except json.JSONDecodeError:
      return R.client_error(message="æ— æ•ˆçš„JSONæ ¼å¼")
    except Exception as e:
      logger.error(f"å¤„ç†å·¥ä½œæµæ–‡ä»¶å¤±è´¥: {e}")
      return R.server_error(message=f"å¤„ç†å·¥ä½œæµå¤±è´¥: {str(e)}")
  
  @router.get("/workflows")
  async def list_workflows():
    """åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„å·¥ä½œæµ"""
    workflows = []
    for file_path in workflow_dir.glob("*.json"):
      try:
        with open(file_path, 'r', encoding='utf-8') as f:
          workflow = json.load(f)
          workflows.append({
            "filename": file_path.name,
            "path": str(file_path),
            "nodes": len(workflow),
            "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
          })
      except:
        continue
    
    return R.success(
      data={"total": len(workflows), "workflows": workflows},
      message="è·å–å·¥ä½œæµåˆ—è¡¨æˆåŠŸ"
    )
  
  @router.get("/workflow/{filename}")
  async def get_workflow(filename: str):
    """è·å–æŒ‡å®šå·¥ä½œæµ"""
    file_path = workflow_dir / filename
    if not file_path.exists():
      return R.not_found(message="å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨")
    
    try:
      with open(file_path, 'r', encoding='utf-8') as f:
        workflow = json.load(f)
      return R.success(
        data={
          "filename": filename,
          "workflow": workflow
        },
        message="è·å–å·¥ä½œæµæˆåŠŸ"
      )
    except Exception as e:
      return R.server_error(message=f"è¯»å–å·¥ä½œæµå¤±è´¥: {str(e)}")
  
  @router.post("/workflow/update")
  async def update_workflow_node(data: WorkflowUpdate):
    """æ›´æ–°å·¥ä½œæµä¸­çš„èŠ‚ç‚¹å‚æ•°"""
    workflow = data.workflow
    node_id = data.node_id
    updates = data.updates
    
    if node_id not in workflow:
      return R.not_found(message=f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
    
    # æ›´æ–°èŠ‚ç‚¹å‚æ•°
    if "inputs" in workflow[node_id]:
      workflow[node_id]["inputs"].update(updates)
    else:
      workflow[node_id]["inputs"] = updates
    
    return R.success(
      data={
        "success": True,
        "workflow": workflow,
        "updated_node": node_id
      },
      message="å·¥ä½œæµèŠ‚ç‚¹æ›´æ–°æˆåŠŸ"
    )
  
  return router


def _convert_ui_to_api_format(raw_workflow: dict) -> dict:
  """
  å°† UI æ ¼å¼çš„å·¥ä½œæµè½¬æ¢ä¸º API æ ¼å¼
  
  Args:
    raw_workflow: UI æ ¼å¼çš„å·¥ä½œæµ
    
  Returns:
    API æ ¼å¼çš„å·¥ä½œæµ
  """
  workflow = {}
  
  # æ„å»ºlinkæ˜ å°„
  link_map = {}  # link_id -> (from_node_id, from_slot)
  if 'links' in raw_workflow and raw_workflow['links']:
    for link in raw_workflow['links']:
      link_id = link[0]
      from_node_id = str(link[1])
      from_slot = link[2]
      link_map[link_id] = (from_node_id, from_slot)
  
  # è½¬æ¢èŠ‚ç‚¹
  for node in raw_workflow['nodes']:
    if 'id' in node:
      node_id = str(node['id'])
      
      # æ„å»ºAPIæ ¼å¼çš„èŠ‚ç‚¹
      api_node = {
        'class_type': node.get('type'),
        'inputs': {}
      }
      
      # å¤„ç†inputs - å°†linksè½¬æ¢ä¸ºèŠ‚ç‚¹å¼•ç”¨
      if 'inputs' in node and isinstance(node['inputs'], list):
        for input_idx, input_def in enumerate(node['inputs']):
          input_name = input_def.get('name', f'input_{input_idx}')
          link_id = input_def.get('link')
          
          if link_id is not None and link_id in link_map:
            from_node_id, from_slot = link_map[link_id]
            api_node['inputs'][input_name] = [from_node_id, from_slot]
      
      # å¤„ç†widgets_values
      if 'widgets_values' in node:
        widget_values = node['widgets_values']
        if 'inputs' in node and isinstance(node['inputs'], list):
          widget_idx = 0
          for input_idx, input_def in enumerate(node['inputs']):
            input_name = input_def.get('name', f'input_{input_idx}')
            link_id = input_def.get('link')
            has_widget = 'widget' in input_def and input_def['widget']
            
            if has_widget and link_id is None and widget_idx < len(widget_values):
              api_node['inputs'][input_name] = widget_values[widget_idx]
              widget_idx += 1
      
      workflow[node_id] = api_node
  
  return workflow

